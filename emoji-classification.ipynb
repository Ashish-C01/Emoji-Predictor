{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":450483,"sourceType":"datasetVersion","datasetId":198119}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom transformers import GPT2Tokenizer\nimport emoji\nfrom transformers import AutoTokenizer,AutoModelForSequenceClassification\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom transformers import Trainer,TrainingArguments\nfrom datasets import Dataset\nfrom transformers import DataCollatorWithPadding\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:37:59.231109Z","iopub.execute_input":"2025-06-13T17:37:59.231455Z","iopub.status.idle":"2025-06-13T17:37:59.237180Z","shell.execute_reply.started":"2025-06-13T17:37:59.231432Z","shell.execute_reply":"2025-06-13T17:37:59.236287Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def create_dataset(filename):\n    data = []\n    sentence = []\n    emojis = []\n\n    with open(f'/kaggle/input/emojifydata-en/{filename}.txt', 'r') as f:\n        for line in tqdm(f):\n            line = line.strip()\n            if not line:\n                if sentence:\n                    sent = \" \".join([w for w in sentence if w not in ['<START>', '<STOP>']])\n                    emjs = \"\".join(emojis)\n                    data.append((sent, emoji.emojize(emjs, language='alias')))\n                    sentence = []\n                    emojis = []\n            else:\n                if len(line.split()) == 2:\n                    word, tag = line.split()\n                    sentence.append(word)\n                    if tag != 'O':\n                        emojis.append(tag)\n\n        # Handle last sentence if file doesnâ€™t end with a newline\n        if sentence:\n            sent = \" \".join([w for w in sentence if w not in ['<START>', '<STOP>']])\n            emjs = \"\".join(emojis)\n            data.append((sent, emoji.emojize(emjs, language='alias')))\n\n    df = pd.DataFrame(data, columns=['Text', 'Emoji'])\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:25:22.495781Z","iopub.execute_input":"2025-06-13T17:25:22.496168Z","iopub.status.idle":"2025-06-13T17:25:22.507052Z","shell.execute_reply.started":"2025-06-13T17:25:22.496145Z","shell.execute_reply":"2025-06-13T17:25:22.506371Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"train_df=create_dataset('train')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:31:10.932178Z","iopub.execute_input":"2025-06-13T11:31:10.932419Z","iopub.status.idle":"2025-06-13T11:32:52.065496Z","shell.execute_reply.started":"2025-06-13T11:31:10.932397Z","shell.execute_reply":"2025-06-13T11:32:52.064908Z"}},"outputs":[{"name":"stderr","text":"99514776it [01:39, 999657.67it/s] \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:32:52.067457Z","iopub.execute_input":"2025-06-13T11:32:52.067670Z","iopub.status.idle":"2025-06-13T11:32:52.088438Z","shell.execute_reply.started":"2025-06-13T11:32:52.067652Z","shell.execute_reply":"2025-06-13T11:32:52.087932Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                Text Emoji\n0  CeeC is going to be another Tboss What is 45 m...     ğŸ˜‚\n1  This gif kills me Death is literally gushing t...     ğŸ˜©\n2                          LOVE TEST Raw Real JaDine     ğŸ’œ\n3             i swear we dont gotta look it finds us     ğŸ˜‚\n4  We would like to wish everyone a very Happy Ne...     ğŸ‰\n5  15000 retweets a new song song off â€œ Swaecatio...    ğŸ—£ï¸\n6                       just know ilysm k bye friend     ğŸ’œ\n7                            Too glam to give a damn     âœ¨\n8                                ğŸ¼ ğŸ¼ fuck that sicko    ğŸ‘ğŸ‘\n9  Can I marry someone who understands all these ...     ğŸ˜­","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Emoji</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CeeC is going to be another Tboss What is 45 m...</td>\n      <td>ğŸ˜‚</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This gif kills me Death is literally gushing t...</td>\n      <td>ğŸ˜©</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOVE TEST Raw Real JaDine</td>\n      <td>ğŸ’œ</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i swear we dont gotta look it finds us</td>\n      <td>ğŸ˜‚</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We would like to wish everyone a very Happy Ne...</td>\n      <td>ğŸ‰</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>15000 retweets a new song song off â€œ Swaecatio...</td>\n      <td>ğŸ—£ï¸</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>just know ilysm k bye friend</td>\n      <td>ğŸ’œ</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Too glam to give a damn</td>\n      <td>âœ¨</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ğŸ¼ ğŸ¼ fuck that sicko</td>\n      <td>ğŸ‘ğŸ‘</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Can I marry someone who understands all these ...</td>\n      <td>ğŸ˜­</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def extract_emoji(text):\n    return [c for c in text if c in emoji.EMOJI_DATA]\ntrain_df['clean emoji']=train_df['Emoji'].apply(extract_emoji)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:02.595295Z","iopub.execute_input":"2025-06-13T11:33:02.595482Z","iopub.status.idle":"2025-06-13T11:33:02.605392Z","shell.execute_reply.started":"2025-06-13T11:33:02.595466Z","shell.execute_reply":"2025-06-13T11:33:02.604846Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                Text Emoji clean emoji\n0  CeeC is going to be another Tboss What is 45 m...     ğŸ˜‚         [ğŸ˜‚]\n1  This gif kills me Death is literally gushing t...     ğŸ˜©         [ğŸ˜©]\n2                          LOVE TEST Raw Real JaDine     ğŸ’œ         [ğŸ’œ]\n3             i swear we dont gotta look it finds us     ğŸ˜‚         [ğŸ˜‚]\n4  We would like to wish everyone a very Happy Ne...     ğŸ‰         [ğŸ‰]\n5  15000 retweets a new song song off â€œ Swaecatio...    ğŸ—£ï¸         [ğŸ—£]\n6                       just know ilysm k bye friend     ğŸ’œ         [ğŸ’œ]\n7                            Too glam to give a damn     âœ¨         [âœ¨]\n8                                ğŸ¼ ğŸ¼ fuck that sicko    ğŸ‘ğŸ‘      [ğŸ‘, ğŸ‘]\n9  Can I marry someone who understands all these ...     ğŸ˜­         [ğŸ˜­]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Emoji</th>\n      <th>clean emoji</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CeeC is going to be another Tboss What is 45 m...</td>\n      <td>ğŸ˜‚</td>\n      <td>[ğŸ˜‚]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This gif kills me Death is literally gushing t...</td>\n      <td>ğŸ˜©</td>\n      <td>[ğŸ˜©]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOVE TEST Raw Real JaDine</td>\n      <td>ğŸ’œ</td>\n      <td>[ğŸ’œ]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i swear we dont gotta look it finds us</td>\n      <td>ğŸ˜‚</td>\n      <td>[ğŸ˜‚]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We would like to wish everyone a very Happy Ne...</td>\n      <td>ğŸ‰</td>\n      <td>[ğŸ‰]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>15000 retweets a new song song off â€œ Swaecatio...</td>\n      <td>ğŸ—£ï¸</td>\n      <td>[ğŸ—£]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>just know ilysm k bye friend</td>\n      <td>ğŸ’œ</td>\n      <td>[ğŸ’œ]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Too glam to give a damn</td>\n      <td>âœ¨</td>\n      <td>[âœ¨]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ğŸ¼ ğŸ¼ fuck that sicko</td>\n      <td>ğŸ‘ğŸ‘</td>\n      <td>[ğŸ‘, ğŸ‘]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Can I marry someone who understands all these ...</td>\n      <td>ğŸ˜­</td>\n      <td>[ğŸ˜­]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_df =  train_df[train_df['clean emoji'].map(len) > 0].sample(n=500_000, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:02.606131Z","iopub.execute_input":"2025-06-13T11:33:02.606438Z","iopub.status.idle":"2025-06-13T11:33:05.836378Z","shell.execute_reply.started":"2025-06-13T11:33:02.606420Z","shell.execute_reply":"2025-06-13T11:33:05.835597Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:05.837233Z","iopub.execute_input":"2025-06-13T11:33:05.837454Z","iopub.status.idle":"2025-06-13T11:33:05.842384Z","shell.execute_reply.started":"2025-06-13T11:33:05.837435Z","shell.execute_reply":"2025-06-13T11:33:05.841722Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(500000, 3)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"emojis_in_data=set()\nfor i in train_df.index:\n    emj=train_df.iloc[i]['clean emoji']\n    for j in emj:\n        emojis_in_data.update(j)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:05.843080Z","iopub.execute_input":"2025-06-13T11:33:05.843319Z","iopub.status.idle":"2025-06-13T11:33:14.656419Z","shell.execute_reply.started":"2025-06-13T11:33:05.843303Z","shell.execute_reply":"2025-06-13T11:33:14.655618Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"emojis_in_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:14.658502Z","iopub.execute_input":"2025-06-13T11:33:14.659108Z","iopub.status.idle":"2025-06-13T11:33:14.664241Z","shell.execute_reply.started":"2025-06-13T11:33:14.659079Z","shell.execute_reply":"2025-06-13T11:33:14.663722Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'â€¼',\n 'â˜º',\n 'â™€',\n 'â™‚',\n 'â™¥',\n 'âœ”',\n 'âœ¨',\n 'â¤',\n 'â¡',\n 'ğŸŒŸ',\n 'ğŸ‰',\n 'ğŸ†',\n 'ğŸ‘€',\n 'ğŸ‘‡',\n 'ğŸ‘‰',\n 'ğŸ‘Œ',\n 'ğŸ‘',\n 'ğŸ‘',\n 'ğŸ’€',\n 'ğŸ’•',\n 'ğŸ’–',\n 'ğŸ’™',\n 'ğŸ’›',\n 'ğŸ’œ',\n 'ğŸ’¥',\n 'ğŸ’ª',\n 'ğŸ’¯',\n 'ğŸ”¥',\n 'ğŸ—£',\n 'ğŸ˜',\n 'ğŸ˜‚',\n 'ğŸ˜‰',\n 'ğŸ˜Š',\n 'ğŸ˜',\n 'ğŸ˜',\n 'ğŸ˜˜',\n 'ğŸ˜¢',\n 'ğŸ˜©',\n 'ğŸ˜­',\n 'ğŸ˜³',\n 'ğŸ™„',\n 'ğŸ™Œ',\n 'ğŸ™',\n 'ğŸš¨',\n 'ğŸ¤”',\n 'ğŸ¤£',\n 'ğŸ¤¦',\n 'ğŸ¤·'}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_df = train_df[train_df['clean emoji'].map(len) > 0].reset_index(drop=True)\ntrain_df\nprint(train_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:14.664885Z","iopub.execute_input":"2025-06-13T11:33:14.665085Z","iopub.status.idle":"2025-06-13T11:33:15.083915Z","shell.execute_reply.started":"2025-06-13T11:33:14.665070Z","shell.execute_reply":"2025-06-13T11:33:15.083217Z"}},"outputs":[{"name":"stdout","text":"(500000, 3)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"mlb=MultiLabelBinarizer()\nemoji_label=mlb.fit_transform(train_df['clean emoji'])\n\nemoji_id_to_label={i:e for i,e in enumerate(mlb.classes_)}\nemoji_label_to_id={e:i for i,e in emoji_id_to_label.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:15.084783Z","iopub.execute_input":"2025-06-13T11:33:15.085082Z","iopub.status.idle":"2025-06-13T11:33:15.732226Z","shell.execute_reply.started":"2025-06-13T11:33:15.085056Z","shell.execute_reply":"2025-06-13T11:33:15.731642Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_df[\"labels\"] = list(emoji_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:15.732916Z","iopub.execute_input":"2025-06-13T11:33:15.733167Z","iopub.status.idle":"2025-06-13T11:33:15.875346Z","shell.execute_reply.started":"2025-06-13T11:33:15.733144Z","shell.execute_reply":"2025-06-13T11:33:15.874697Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True)\nnum_labels=emoji_label.shape[1]\nmodel=AutoModelForSequenceClassification.from_pretrained(\n    \"vinai/bertweet-base\",\n    num_labels=num_labels,\n    problem_type=\"multi_label_classification\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:15.876239Z","iopub.execute_input":"2025-06-13T11:33:15.876506Z","iopub.status.idle":"2025-06-13T11:33:21.272496Z","shell.execute_reply.started":"2025-06-13T11:33:15.876484Z","shell.execute_reply":"2025-06-13T11:33:21.271845Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad21f3f43614c8e81f826f47c053b93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fb45b7250cd45908e68f8f30dcc4dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1b5067d865475091dee5c98379bcd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da2ad6be1c8b463cae9ed8e9d5d56f45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0238d4fe92f44f059fc0fd66e11273f9"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"dataset = Dataset.from_pandas(train_df[[\"Text\", \"labels\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:33:21.273321Z","iopub.execute_input":"2025-06-13T11:33:21.273582Z","iopub.status.idle":"2025-06-13T11:33:23.379959Z","shell.execute_reply.started":"2025-06-13T11:33:21.273556Z","shell.execute_reply":"2025-06-13T11:33:23.379075Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2acac34163e64025b7e15016b3c2a614"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def tokenize_function(example):\n    tokens = tokenizer(\n        example[\"Text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128\n    )\n    tokens[\"labels\"] = example[\"labels\"]\n    return tokens\n    \ntokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ntokenized_dataset = tokenized_dataset.map(\n    lambda x: {\"labels\": [list(map(float, l)) for l in x[\"labels\"]]},\n    batched=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:34:32.806305Z","iopub.execute_input":"2025-06-13T11:34:32.807074Z","iopub.status.idle":"2025-06-13T11:35:15.283992Z","shell.execute_reply.started":"2025-06-13T11:34:32.807049Z","shell.execute_reply":"2025-06-13T11:35:15.283368Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90925f8568c4e74bae4b1cd4367b606"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"class CustomDataCollator(DataCollatorWithPadding):\n    def __call__(self, features):\n        for f in features:\n            f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n        return super().__call__(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:31:33.182189Z","iopub.execute_input":"2025-06-13T17:31:33.182525Z","iopub.status.idle":"2025-06-13T17:31:33.187080Z","shell.execute_reply.started":"2025-06-13T17:31:33.182507Z","shell.execute_reply":"2025-06-13T17:31:33.186246Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:35:15.289852Z","iopub.execute_input":"2025-06-13T11:35:15.290078Z","iopub.status.idle":"2025-06-13T11:35:15.307090Z","shell.execute_reply.started":"2025-06-13T11:35:15.290055Z","shell.execute_reply":"2025-06-13T11:35:15.306457Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"data_collator = CustomDataCollator(tokenizer=tokenizer)\ntraining_args = TrainingArguments(\n    output_dir='tweet-emoji',\n    per_device_train_batch_size=16,\n    num_train_epochs=2,\n    save_strategy='epoch',\n    logging_steps=1000,\n    # evaluation_strategy=\"no\",\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:35:15.307989Z","iopub.execute_input":"2025-06-13T11:35:15.308236Z","iopub.status.idle":"2025-06-13T15:14:31.750940Z","shell.execute_reply.started":"2025-06-13T11:35:15.308215Z","shell.execute_reply":"2025-06-13T15:14:31.750135Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2978934322.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/tmp/ipykernel_35/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [62500/62500 3:39:13, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.116700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.087800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.083800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.082100</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.079300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.077600</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.077200</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.075700</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.074800</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.074400</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.073200</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.072800</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.072300</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.072200</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.071500</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.071200</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.070900</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.070400</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.070600</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.070200</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.069300</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>0.069200</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>0.069100</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>0.068800</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>0.068900</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>0.068000</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>0.067400</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>0.067700</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>0.067600</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>0.067100</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>0.063400</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>0.062600</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>0.062900</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>0.062600</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>0.061600</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>0.062200</td>\n    </tr>\n    <tr>\n      <td>38000</td>\n      <td>0.062200</td>\n    </tr>\n    <tr>\n      <td>39000</td>\n      <td>0.061800</td>\n    </tr>\n    <tr>\n      <td>40000</td>\n      <td>0.061600</td>\n    </tr>\n    <tr>\n      <td>41000</td>\n      <td>0.061100</td>\n    </tr>\n    <tr>\n      <td>42000</td>\n      <td>0.060800</td>\n    </tr>\n    <tr>\n      <td>43000</td>\n      <td>0.060000</td>\n    </tr>\n    <tr>\n      <td>44000</td>\n      <td>0.060900</td>\n    </tr>\n    <tr>\n      <td>45000</td>\n      <td>0.060500</td>\n    </tr>\n    <tr>\n      <td>46000</td>\n      <td>0.060200</td>\n    </tr>\n    <tr>\n      <td>47000</td>\n      <td>0.060400</td>\n    </tr>\n    <tr>\n      <td>48000</td>\n      <td>0.060100</td>\n    </tr>\n    <tr>\n      <td>49000</td>\n      <td>0.060000</td>\n    </tr>\n    <tr>\n      <td>50000</td>\n      <td>0.060000</td>\n    </tr>\n    <tr>\n      <td>51000</td>\n      <td>0.060300</td>\n    </tr>\n    <tr>\n      <td>52000</td>\n      <td>0.060100</td>\n    </tr>\n    <tr>\n      <td>53000</td>\n      <td>0.059400</td>\n    </tr>\n    <tr>\n      <td>54000</td>\n      <td>0.059000</td>\n    </tr>\n    <tr>\n      <td>55000</td>\n      <td>0.059400</td>\n    </tr>\n    <tr>\n      <td>56000</td>\n      <td>0.059800</td>\n    </tr>\n    <tr>\n      <td>57000</td>\n      <td>0.058800</td>\n    </tr>\n    <tr>\n      <td>58000</td>\n      <td>0.059100</td>\n    </tr>\n    <tr>\n      <td>59000</td>\n      <td>0.058300</td>\n    </tr>\n    <tr>\n      <td>60000</td>\n      <td>0.059100</td>\n    </tr>\n    <tr>\n      <td>61000</td>\n      <td>0.059700</td>\n    </tr>\n    <tr>\n      <td>62000</td>\n      <td>0.059000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=62500, training_loss=0.0674023611755371, metrics={'train_runtime': 13154.7956, 'train_samples_per_second': 76.018, 'train_steps_per_second': 4.751, 'total_flos': 6.5804931072e+16, 'train_loss': 0.0674023611755371, 'epoch': 2.0})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"! mkdir /kaggle/working/model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:14:45.284609Z","iopub.execute_input":"2025-06-13T15:14:45.285259Z","iopub.status.idle":"2025-06-13T15:14:45.609420Z","shell.execute_reply.started":"2025-06-13T15:14:45.285238Z","shell.execute_reply":"2025-06-13T15:14:45.608580Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model_dir='model'\nmodel.save_pretrained(model_dir,save_serialization=True)\ntokenizer.save_pretrained(model_dir)\njoblib.dump(mlb,'model\\mlb_emoji_encoder.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:15:28.511602Z","iopub.execute_input":"2025-06-13T15:15:28.511910Z","iopub.status.idle":"2025-06-13T15:15:29.366551Z","shell.execute_reply.started":"2025-06-13T15:15:28.511858Z","shell.execute_reply":"2025-06-13T15:15:29.365930Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['model\\\\mlb_emoji_encoder.pkl']"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"joblib.dump(mlb,'/kaggle/working/model/mlb_emoji_encoder.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:16:20.045383Z","iopub.execute_input":"2025-06-13T15:16:20.046372Z","iopub.status.idle":"2025-06-13T15:16:20.376409Z","shell.execute_reply.started":"2025-06-13T15:16:20.046343Z","shell.execute_reply":"2025-06-13T15:16:20.375679Z"}},"outputs":[{"name":"stdout","text":"mkdir: missing operand\nTry 'mkdir --help' for more information.\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/model/mlb_emoji_encoder.pkl']"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"mlb.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:17:43.086133Z","iopub.execute_input":"2025-06-13T15:17:43.086634Z","iopub.status.idle":"2025-06-13T15:17:43.091680Z","shell.execute_reply.started":"2025-06-13T15:17:43.086601Z","shell.execute_reply":"2025-06-13T15:17:43.091121Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array(['â€¼', 'â˜º', 'â™€', 'â™‚', 'â™¥', 'âœ”', 'âœ¨', 'â¤', 'â¡', 'ğŸŒŸ', 'ğŸ‰', 'ğŸ†', 'ğŸ‘€',\n       'ğŸ‘‡', 'ğŸ‘‰', 'ğŸ‘Œ', 'ğŸ‘', 'ğŸ‘', 'ğŸ’€', 'ğŸ’•', 'ğŸ’–', 'ğŸ’™', 'ğŸ’›', 'ğŸ’œ', 'ğŸ’¥', 'ğŸ’ª',\n       'ğŸ’¯', 'ğŸ”¥', 'ğŸ—£', 'ğŸ˜', 'ğŸ˜‚', 'ğŸ˜‰', 'ğŸ˜Š', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜˜', 'ğŸ˜¢', 'ğŸ˜©', 'ğŸ˜­',\n       'ğŸ˜³', 'ğŸ™„', 'ğŸ™Œ', 'ğŸ™', 'ğŸš¨', 'ğŸ¤”', 'ğŸ¤£', 'ğŸ¤¦', 'ğŸ¤·'], dtype=object)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import shutil\nshutil.make_archive('tweet_emoji_bert', 'zip', '/kaggle/working/model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:17:48.124645Z","iopub.execute_input":"2025-06-13T15:17:48.124947Z","iopub.status.idle":"2025-06-13T15:18:16.322540Z","shell.execute_reply.started":"2025-06-13T15:17:48.124926Z","shell.execute_reply":"2025-06-13T15:18:16.321935Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/tweet_emoji_bert.zip'"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"! pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:18:58.752035Z","iopub.execute_input":"2025-06-13T15:18:58.752732Z","iopub.status.idle":"2025-06-13T15:19:04.729026Z","shell.execute_reply.started":"2025-06-13T15:18:58.752702Z","shell.execute_reply":"2025-06-13T15:19:04.728097Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import evaluate\nfrom sklearn.metrics import accuracy_score,f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:56:50.337845Z","iopub.execute_input":"2025-06-13T17:56:50.338608Z","iopub.status.idle":"2025-06-13T17:56:50.448322Z","shell.execute_reply.started":"2025-06-13T17:56:50.338585Z","shell.execute_reply":"2025-06-13T17:56:50.447746Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n    preds = (probs > 0.5).astype(int)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='micro')\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:19:25.941057Z","iopub.execute_input":"2025-06-13T15:19:25.941588Z","iopub.status.idle":"2025-06-13T15:19:25.945730Z","shell.execute_reply.started":"2025-06-13T15:19:25.941564Z","shell.execute_reply":"2025-06-13T15:19:25.945007Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"model\")\ntokenizer = AutoTokenizer.from_pretrained(\"model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:19:29.680557Z","iopub.execute_input":"2025-06-13T15:19:29.681133Z","iopub.status.idle":"2025-06-13T15:19:29.882392Z","shell.execute_reply.started":"2025-06-13T15:19:29.681107Z","shell.execute_reply":"2025-06-13T15:19:29.881811Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    data_collator=data_collator,  \n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T16:13:48.279254Z","iopub.execute_input":"2025-06-13T16:13:48.279515Z","iopub.status.idle":"2025-06-13T16:13:48.317180Z","shell.execute_reply.started":"2025-06-13T16:13:48.279498Z","shell.execute_reply":"2025-06-13T16:13:48.316643Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3684618998.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntrain_metrics = trainer.evaluate(eval_dataset=tokenized_dataset)\nprint(\"Training Set Metrics:\", train_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T16:13:51.408862Z","iopub.execute_input":"2025-06-13T16:13:51.409568Z","iopub.status.idle":"2025-06-13T16:48:26.486195Z","shell.execute_reply.started":"2025-06-13T16:13:51.409546Z","shell.execute_reply":"2025-06-13T16:48:26.485422Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [62500/62500 34:25]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training Set Metrics: {'eval_loss': 0.05261430889368057, 'eval_model_preparation_time': 0.0033, 'eval_accuracy': 0.398562, 'eval_f1': 0.5596929174318587, 'eval_runtime': 2075.0598, 'eval_samples_per_second': 240.957, 'eval_steps_per_second': 30.12}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"valid_df=create_dataset('test')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_df['clean emoji']=valid_df['Emoji'].apply(extract_emoji)\nemoji_label=mlb.transform(valid_df['clean emoji'])\nvalid_df[\"labels\"] = list(emoji_label)\n\nval_dataset = Dataset.from_pandas(valid_df[[\"Text\", \"labels\"]])\nval_tokenized_dataset = val_dataset.map(tokenize_function, batched=True, num_proc=4)\nval_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nval_tokenized_dataset = val_tokenized_dataset.map(\n    lambda x: {\"labels\": [list(map(float, l)) for l in x[\"labels\"]]},\n    batched=True\n)\nval_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\nval_metrics = trainer.evaluate(eval_dataset=val_tokenized_dataset)\nprint(\"Validation Set Metrics:\", val_metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediction Part","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"model\")\ntokenizer = AutoTokenizer.from_pretrained(\"model\")\nmlb=joblib.load('/kaggle/working/model/mlb_emoji_encoder.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T18:56:42.340532Z","iopub.execute_input":"2025-06-13T18:56:42.341224Z","iopub.status.idle":"2025-06-13T18:56:42.537926Z","shell.execute_reply.started":"2025-06-13T18:56:42.341188Z","shell.execute_reply":"2025-06-13T18:56:42.537100Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T18:56:43.679284Z","iopub.execute_input":"2025-06-13T18:56:43.679807Z","iopub.status.idle":"2025-06-13T18:56:43.685728Z","shell.execute_reply.started":"2025-06-13T18:56:43.679783Z","shell.execute_reply":"2025-06-13T18:56:43.685169Z"}},"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(130, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=48, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":141},{"cell_type":"code","source":"def predict_emojis(text):\n    model.eval()\n    inputs=tokenizer(\n        text,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128,\n        return_tensors=\"pt\"\n    )\n\n    with torch.no_grad():\n        outputs=model(**inputs)\n        print(outputs.logits)\n        probs=torch.sigmoid(outputs.logits)\n        print(probs)\n        predictions=(probs>=0.3).int().numpy()\n    print(predictions)\n\n    return mlb.inverse_transform(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:21:21.727816Z","iopub.execute_input":"2025-06-13T17:21:21.728604Z","iopub.status.idle":"2025-06-13T17:21:21.734021Z","shell.execute_reply.started":"2025-06-13T17:21:21.728567Z","shell.execute_reply":"2025-06-13T17:21:21.733166Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"predict_emojis(\"It is gonna be fun today, will play games and do fun activities\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:21:12.676980Z","iopub.execute_input":"2025-06-13T17:21:12.677498Z","iopub.status.idle":"2025-06-13T17:21:12.820130Z","shell.execute_reply.started":"2025-06-13T17:21:12.677475Z","shell.execute_reply":"2025-06-13T17:21:12.819381Z"}},"outputs":[{"name":"stdout","text":"tensor([[-9.9818, -3.2426, -7.5848, -9.5882, -5.2063, -6.5351, -3.4494, -3.4749,\n         -8.4590, -5.3543, -4.9825, -7.8210, -5.3048, -6.4848, -6.7298, -4.4016,\n         -3.0211, -5.8498, -7.4705, -2.6714, -3.8847, -4.0045, -4.1654, -3.9560,\n         -7.2476, -5.9317, -6.0126, -6.0635, -7.9244, -2.0577, -2.8466, -2.5008,\n         -0.2568, -3.1581, -3.9901, -3.1193, -6.1196, -5.9622, -4.9209, -6.3456,\n         -4.9971, -5.3569, -4.7934, -8.4494, -5.0017, -5.1919, -9.6236, -6.9423]])\ntensor([[4.6230e-05, 3.7592e-02, 5.0787e-04, 6.8531e-05, 5.4521e-03, 1.4494e-03,\n         3.0786e-02, 3.0036e-02, 2.1194e-04, 4.7054e-03, 6.8100e-03, 4.0108e-04,\n         4.9432e-03, 1.5242e-03, 1.1933e-03, 1.2109e-02, 4.6481e-02, 2.8721e-03,\n         5.6934e-04, 6.4679e-02, 2.0140e-02, 1.7908e-02, 1.5287e-02, 1.8780e-02,\n         7.1138e-04, 2.6469e-03, 2.4416e-03, 2.3208e-03, 3.6169e-04, 1.1328e-01,\n         5.4859e-02, 7.5801e-02, 4.3615e-01, 4.0774e-02, 1.8161e-02, 4.2316e-02,\n         2.1946e-03, 2.5677e-03, 7.2394e-03, 1.7513e-03, 6.7119e-03, 4.6935e-03,\n         8.2165e-03, 2.1399e-04, 6.6814e-03, 5.5307e-03, 6.6142e-05, 9.6516e-04]])\n[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 0]]\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"[('ğŸ˜Š',)]"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"predict_emojis(\"It is gonna be boring today, I don't have anything to do\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:21:24.276190Z","iopub.execute_input":"2025-06-13T17:21:24.276692Z","iopub.status.idle":"2025-06-13T17:21:24.423582Z","shell.execute_reply.started":"2025-06-13T17:21:24.276666Z","shell.execute_reply":"2025-06-13T17:21:24.422731Z"}},"outputs":[{"name":"stdout","text":"tensor([[-10.3065,  -6.8796,  -7.9452,  -9.8666,  -8.4167,  -9.4749,  -6.8766,\n          -6.6593, -10.2658,  -8.7952,  -7.2954,  -9.4924,  -6.0826,  -8.7549,\n          -9.4072,  -6.9320,  -6.5513,  -6.2663,  -5.2185,  -6.2692,  -6.9855,\n          -7.2521,  -7.4664,  -7.4758,  -7.7659,  -7.4456,  -5.9887,  -6.6328,\n          -7.1367,  -5.2754,  -2.7389,  -6.2015,  -4.4402,  -5.4425,  -6.3196,\n          -6.8769,  -2.4257,  -0.9126,  -0.7196,  -5.1986,  -1.3077,  -6.6778,\n          -5.7267,  -8.6202,  -4.1181,  -5.3393,  -6.4791,  -7.3667]])\ntensor([[3.3415e-05, 1.0275e-03, 3.5424e-04, 5.1877e-05, 2.2110e-04, 7.6748e-05,\n         1.0306e-03, 1.2804e-03, 3.4801e-05, 1.5144e-04, 6.7823e-04, 7.5414e-05,\n         2.2771e-03, 1.5766e-04, 8.2122e-05, 9.7507e-04, 1.4262e-03, 1.8957e-03,\n         5.3865e-03, 1.8901e-03, 9.2437e-04, 7.0817e-04, 5.7166e-04, 5.6632e-04,\n         4.2378e-04, 5.8367e-04, 2.5007e-03, 1.3148e-03, 7.9476e-04, 5.0901e-03,\n         6.0714e-02, 2.0223e-03, 1.1656e-02, 4.3100e-03, 1.7975e-03, 1.0303e-03,\n         8.1237e-02, 2.8646e-01, 3.2748e-01, 5.4941e-03, 2.1288e-01, 1.2570e-03,\n         3.2472e-03, 1.8039e-04, 1.6015e-02, 4.7764e-03, 1.5328e-03, 6.3157e-04]])\n[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 1 0 0 0 0 0 0 0 0 0]]\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"[('ğŸ˜­',)]"},"metadata":{}}],"execution_count":46},{"cell_type":"markdown","source":"## Finding correct threshold","metadata":{}},{"cell_type":"code","source":"valid_df=create_dataset('dev')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:26:23.286096Z","iopub.execute_input":"2025-06-13T17:26:23.286932Z","iopub.status.idle":"2025-06-13T17:26:47.775925Z","shell.execute_reply.started":"2025-06-13T17:26:23.286902Z","shell.execute_reply":"2025-06-13T17:26:47.775328Z"}},"outputs":[{"name":"stderr","text":"24885251it [00:24, 1033217.78it/s]\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"valid_df['clean emoji']=valid_df['Emoji'].apply(extract_emoji)\nvalid_df = valid_df[valid_df['clean emoji'].map(len) > 0].sample(n=10000, random_state=42).reset_index(drop=True)\n\nemoji_label=mlb.transform(valid_df['clean emoji'])\nvalid_df[\"labels\"] = list(emoji_label)\n\nval_dataset = Dataset.from_pandas(valid_df[[\"Text\", \"labels\"]])\n\nval_tokenized_dataset = val_dataset.map(tokenize_function, batched=True, num_proc=4)\nval_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nval_tokenized_dataset = val_tokenized_dataset.map(\n    lambda x: {\"labels\": [list(map(float, l)) for l in x[\"labels\"]]},\n    batched=True\n)\n\nval_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ndata_collator = CustomDataCollator(tokenizer=tokenizer)\n\nvalid_loader=DataLoader(val_tokenized_dataset,batch_size=32,collate_fn=data_collator)\n\nmodel.eval()\nall_logits=[]\nall_labels=[]\n\ndevice=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nwith torch.no_grad():\n    for batch in valid_loader:\n        input_ids=batch['input_ids'].to(model.device)\n        attention_mask=batch['attention_mask'].to(model.device)\n        labels=batch['labels'].to(model.device)\n\n        outputs=model(input_ids=input_ids,attention_mask=attention_mask)\n        logits=outputs.logits\n\n        all_logits.append(logits.cpu())\n        all_labels.append(labels.cpu())\n\nlogits=torch.cat(all_logits).numpy()\nlabels=torch.cat(all_labels).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:55:38.193310Z","iopub.execute_input":"2025-06-13T17:55:38.194111Z","iopub.status.idle":"2025-06-13T17:56:17.252623Z","shell.execute_reply.started":"2025-06-13T17:55:38.194084Z","shell.execute_reply":"2025-06-13T17:56:17.251672Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d32fa1dd1264d1694bb3aa9e7c05324"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f81f0393d84fe5bb121241e307e021"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_386/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"def tune_thresholds(y_true,y_probs):\n    thresholds=[]\n    for i in range(y_true.shape[1]):\n        if y_true[:,i].sum()==0:\n            threshold.append(0.5)\n            continue\n        best_thresh=0.5\n        best_f1=0\n        for thresh in np.arange(0.1,0.9,0.05):\n            preds=(y_probs[:,i]>=thresh).astype(int)\n            score=f1_score(y_true[:,i],preds,zero_division=0)\n            if score>best_f1:\n                best_f1=score\n                best_thresh=thresh\n        thresholds.append(best_thresh)\n    return np.array(thresholds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:56:35.760628Z","iopub.execute_input":"2025-06-13T17:56:35.761243Z","iopub.status.idle":"2025-06-13T17:56:35.766906Z","shell.execute_reply.started":"2025-06-13T17:56:35.761212Z","shell.execute_reply":"2025-06-13T17:56:35.766039Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"tuned_thresholds_=tune_thresholds(labels,logits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:56:55.353139Z","iopub.execute_input":"2025-06-13T17:56:55.353849Z","iopub.status.idle":"2025-06-13T17:56:59.750524Z","shell.execute_reply.started":"2025-06-13T17:56:55.353825Z","shell.execute_reply":"2025-06-13T17:56:59.749615Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"missing_classes = np.where(labels.sum(axis=0) == 0)[0]\nprint(f\"Classes not present in validation set: {missing_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T17:58:45.040480Z","iopub.execute_input":"2025-06-13T17:58:45.040765Z","iopub.status.idle":"2025-06-13T17:58:45.045896Z","shell.execute_reply.started":"2025-06-13T17:58:45.040745Z","shell.execute_reply":"2025-06-13T17:58:45.045189Z"}},"outputs":[{"name":"stdout","text":"Classes not present in validation set: []\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"tuned_thresholds_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T18:00:55.236845Z","iopub.execute_input":"2025-06-13T18:00:55.237426Z","iopub.status.idle":"2025-06-13T18:00:55.242853Z","shell.execute_reply.started":"2025-06-13T18:00:55.237403Z","shell.execute_reply":"2025-06-13T18:00:55.242123Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"array([0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.15, 0.1 , 0.1 , 0.15, 0.25,\n       0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.3 , 0.5 , 0.1 , 0.1 ,\n       0.5 , 0.1 , 0.5 , 0.1 , 0.1 , 0.1 , 0.1 , 0.5 , 0.1 , 0.5 , 0.1 ,\n       0.1 , 0.5 , 0.1 , 0.1 , 0.35, 0.1 , 0.1 , 0.1 , 0.1 , 0.2 , 0.15,\n       0.25, 0.5 , 0.1 , 0.1 ])"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"model.to('cpu')\ndef predict_emojis(text):\n    thresholds=np.array([0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.15, 0.1 , 0.1 , 0.15, 0.25,\n       0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.3 , 0.5 , 0.1 , 0.1 ,\n       0.5 , 0.1 , 0.5 , 0.1 , 0.1 , 0.1 , 0.1 , 0.5 , 0.1 , 0.5 , 0.1 ,\n       0.1 , 0.5 , 0.1 , 0.1 , 0.35, 0.1 , 0.1 , 0.1 , 0.1 , 0.2 , 0.15,\n       0.25, 0.5 , 0.1 , 0.1 ])\n    model.eval()\n    inputs=tokenizer(\n        text,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128,\n        return_tensors=\"pt\"\n    )\n    predictions=[]\n    with torch.no_grad():\n        outputs=model(**inputs)\n        probs=torch.sigmoid(outputs.logits).squeeze(0).numpy()\n\n    predicted_labels=(probs>=thresholds).astype(int).reshape(1,-1)\n\n    return mlb.inverse_transform(predicted_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T18:56:55.702404Z","iopub.execute_input":"2025-06-13T18:56:55.703005Z","iopub.status.idle":"2025-06-13T18:56:55.712589Z","shell.execute_reply.started":"2025-06-13T18:56:55.702980Z","shell.execute_reply":"2025-06-13T18:56:55.711840Z"}},"outputs":[],"execution_count":142},{"cell_type":"code","source":"predict_emojis(\"It is gonna be boring today, I don't have anything to do\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T18:56:56.696354Z","iopub.execute_input":"2025-06-13T18:56:56.697095Z","iopub.status.idle":"2025-06-13T18:56:56.870990Z","shell.execute_reply.started":"2025-06-13T18:56:56.697068Z","shell.execute_reply":"2025-06-13T18:56:56.870355Z"}},"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"[('ğŸ˜­', 'ğŸ™„')]"},"metadata":{}}],"execution_count":143},{"cell_type":"code","source":"predict_emojis(\"It is gonna be fun today, will play games and do fun activities. Lets go!!!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T18:56:58.093331Z","iopub.execute_input":"2025-06-13T18:56:58.093621Z","iopub.status.idle":"2025-06-13T18:56:58.251709Z","shell.execute_reply.started":"2025-06-13T18:56:58.093600Z","shell.execute_reply":"2025-06-13T18:56:58.251069Z"}},"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"[('ğŸ’ª', 'ğŸ”¥')]"},"metadata":{}}],"execution_count":144},{"cell_type":"markdown","source":"# Quantize","metadata":{}},{"cell_type":"code","source":"! pip install onnx onnxruntime optimum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:19:14.376433Z","iopub.execute_input":"2025-06-14T14:19:14.376862Z","iopub.status.idle":"2025-06-14T14:21:07.220262Z","shell.execute_reply.started":"2025-06-14T14:19:14.376825Z","shell.execute_reply":"2025-06-14T14:21:07.218705Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\nCollecting onnxruntime\n  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nCollecting optimum\n  Downloading optimum-1.26.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (3.20.3)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum) (4.51.3)\nRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum) (0.31.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (2025.3.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11->optimum)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11->optimum)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11->optimum)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11->optimum)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11->optimum)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11->optimum)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11->optimum)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.5.3)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->onnx) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->onnx) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->onnx) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->onnx) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2025.4.26)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->onnx) (2024.2.0)\nDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading optimum-1.26.1-py3-none-any.whl (424 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m424.6/424.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, humanfriendly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, nvidia-cusolver-cu12, optimum, onnxruntime\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.22.0 optimum-1.26.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"! pip install --upgrade optimum[onnxruntime] transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:44:21.980547Z","iopub.execute_input":"2025-06-14T14:44:21.981078Z","iopub.status.idle":"2025-06-14T14:44:39.541100Z","shell.execute_reply.started":"2025-06-14T14:44:21.981046Z","shell.execute_reply":"2025-06-14T14:44:39.539523Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nCollecting transformers\n  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: optimum[onnxruntime] in /usr/local/lib/python3.11/dist-packages (1.26.1)\nRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (2.6.0+cu124)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (25.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (0.31.1)\nRequirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (1.17.0)\nRequirement already satisfied: datasets>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (3.6.0)\nRequirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (3.20.3)\nRequirement already satisfied: onnxruntime>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from optimum[onnxruntime]) (1.22.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime])\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optimum[onnxruntime]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optimum[onnxruntime]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optimum[onnxruntime]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optimum[onnxruntime]) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optimum[onnxruntime]) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optimum[onnxruntime]) (2.4.1)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]) (25.2.10)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]) (1.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[onnxruntime]) (3.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.11.0->optimum[onnxruntime]) (1.3.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (3.11.18)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.11.0->optimum[onnxruntime]) (10.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum[onnxruntime]) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optimum[onnxruntime]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optimum[onnxruntime]) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optimum[onnxruntime]) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optimum[onnxruntime]) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.2.1->optimum[onnxruntime]) (1.20.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optimum[onnxruntime]) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.2.1->optimum[onnxruntime]) (1.17.0)\nDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, transformers\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.3\n    Uninstalling transformers-4.51.3:\n      Successfully uninstalled transformers-4.51.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0 transformers-4.52.4\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from transformers.onnx import export\nfrom pathlib import Path\nfrom transformers.onnx.features import FeaturesManager\nfrom onnxruntime.quantization import quantize_dynamic,QuantType\nimport onnxruntime as ort\nimport onnx\nfrom optimum.exporters.tasks import TasksManager\nfrom transformers import AutoTokenizer,AutoModelForSequenceClassification\nimport numpy as np\nfrom optimum.onnxruntime import ORTQuantizer\nfrom optimum.onnxruntime.configuration import AutoQuantizationConfig\nfrom optimum.onnxruntime import ORTModelForSequenceClassification, ORTQuantizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:44:46.264864Z","iopub.execute_input":"2025-06-14T14:44:46.265245Z","iopub.status.idle":"2025-06-14T14:44:46.272831Z","shell.execute_reply.started":"2025-06-14T14:44:46.265216Z","shell.execute_reply":"2025-06-14T14:44:46.271504Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model=AutoModelForSequenceClassification.from_pretrained(\"ashish-001/tweet-emoji-predictor\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:26:00.821278Z","iopub.execute_input":"2025-06-14T14:26:00.822003Z","iopub.status.idle":"2025-06-14T14:26:04.028008Z","shell.execute_reply.started":"2025-06-14T14:26:00.821967Z","shell.execute_reply":"2025-06-14T14:26:04.026671Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80be1272962d4f438b8a4f6a806f0e49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"215c5ac5c2a047dfb395a55b397b5572"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(\"ashish-001/tweet-emoji-predictor\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T14:26:20.815306Z","iopub.execute_input":"2025-06-14T14:26:20.815685Z","iopub.status.idle":"2025-06-14T14:26:23.158426Z","shell.execute_reply.started":"2025-06-14T14:26:20.815658Z","shell.execute_reply":"2025-06-14T14:26:23.157353Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8211156ab14009881b04cc3e4a6bce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f702295590bf4d128b08209087176293"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df5875c0c46c4df6b7c6134fd423bd41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2868e870344d427e8a5f0b1a24d2e697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0174378a31244ddda3c6c5e40f6b4eef"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"PYTORCH_MODEL_DIR = \"ashish-001/tweet-emoji-predictor\"  \nONNX_UNQUANTIZED_DIR = Path(\"onnx_unquantized\")\nQUANTIZED_MODEL_DIR = Path(\"onnx_quantized_dynamic\")\n\nprint(\"STAGE 1: Exporting PyTorch model to ONNX ---\")\n\n\nmodel = ORTModelForSequenceClassification.from_pretrained(\n    PYTORCH_MODEL_DIR,\n    export=True\n)\ntokenizer = AutoTokenizer.from_pretrained(PYTORCH_MODEL_DIR)\n\n\nmodel.save_pretrained(ONNX_UNQUANTIZED_DIR)\ntokenizer.save_pretrained(ONNX_UNQUANTIZED_DIR)\n\nprint(f\"Unquantized ONNX model saved to: {ONNX_UNQUANTIZED_DIR}\")\n\n\nprint(\"STAGE 2: Applying Dynamic Quantization ---\")\n\n\nquantizer = ORTQuantizer.from_pretrained(ONNX_UNQUANTIZED_DIR)\n\n\ndqconfig = AutoQuantizationConfig.avx2(is_static=False, per_channel=False)\n\n\nquantizer.quantize(\n    save_dir=QUANTIZED_MODEL_DIR,\n    quantization_config=dqconfig,\n)\n\nprint(f\"Dynamically quantized model saved to: {QUANTIZED_MODEL_DIR}\")\n\n\nprint(\"STAGE 3: Running Inference ---\")\n\n\nquantized_model_path = QUANTIZED_MODEL_DIR / \"model_quantized.onnx\"\n\nsession = ort.InferenceSession(str(quantized_model_path))\n\n\ntext = \"This is a sample text for inference.\"\ninputs = tokenizer(text, return_tensors=\"np\")\n\n\nonnx_inputs = {\n    \"input_ids\": inputs[\"input_ids\"].astype(np.int64),\n    \"attention_mask\": inputs[\"attention_mask\"].astype(np.int64),\n}\n\n\nlogits = session.run(None, onnx_inputs)[0]\n\nprint(\"Inference successful!\")\nprint(\"Logits shape:\", logits.shape)\nprobabilities = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\nprint(\"Probabilities:\", probabilities)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comparing finetuned model and onnxruntime","metadata":{}},{"cell_type":"code","source":"import time\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:54:23.539367Z","iopub.execute_input":"2025-06-14T15:54:23.539817Z","iopub.status.idle":"2025-06-14T15:54:23.547235Z","shell.execute_reply.started":"2025-06-14T15:54:23.539761Z","shell.execute_reply":"2025-06-14T15:54:23.545652Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"model=AutoModelForSequenceClassification.from_pretrained(\"ashish-001/tweet-emoji-predictor\")\nsession = ort.InferenceSession(str(quantized_model_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:47:15.086081Z","iopub.execute_input":"2025-06-14T15:47:15.086650Z","iopub.status.idle":"2025-06-14T15:47:16.741395Z","shell.execute_reply.started":"2025-06-14T15:47:15.086608Z","shell.execute_reply":"2025-06-14T15:47:16.739332Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:47:34.116133Z","iopub.execute_input":"2025-06-14T15:47:34.116501Z","iopub.status.idle":"2025-06-14T15:47:34.128523Z","shell.execute_reply.started":"2025-06-14T15:47:34.116474Z","shell.execute_reply":"2025-06-14T15:47:34.126846Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(130, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=48, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"text=\"Sample input for timing comparison\"\ninput_pt=tokenizer(text,return_tensors=\"pt\")\n\nfor _ in range(5):\n    with torch.no_grad():\n        _=model(**input_pt)\n\n# Measure\nstart_time=time.time()\nfor _ in range(100):\n    with torch.no_grad():\n        _=model(**input_pt)\nend_time=time.time()\n\navg_pt_time=(end_time-start_time)/100\nprint(f\"Average PyTorch inference time: {avg_pt_time:.6f} sec\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:54:34.304149Z","iopub.execute_input":"2025-06-14T15:54:34.305226Z","iopub.status.idle":"2025-06-14T15:54:42.819452Z","shell.execute_reply.started":"2025-06-14T15:54:34.305183Z","shell.execute_reply":"2025-06-14T15:54:42.818459Z"}},"outputs":[{"name":"stdout","text":"Average PyTorch inference time: 0.079958 sec\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"input_np=tokenizer(text,return_tensors=\"np\")\nonnx_inputs = {\n    \"input_ids\": input_np[\"input_ids\"].astype(np.int64),\n    \"attention_mask\": input_np[\"attention_mask\"].astype(np.int64),\n}\n\nfor _ in range(5):\n    with torch.no_grad():\n        _=session.run(None,onnx_inputs)\n\n# Measure\nstart_time=time.time()\nfor _ in range(100):\n    with torch.no_grad():\n        _=session.run(None,onnx_inputs)\nend_time=time.time()\n\navg_onnx_time=(end_time-start_time)/100\nprint(f\"Average ONNX inference time: {avg_onnx_time:.6f} sec\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:56:26.822820Z","iopub.execute_input":"2025-06-14T15:56:26.823196Z","iopub.status.idle":"2025-06-14T15:56:29.665005Z","shell.execute_reply.started":"2025-06-14T15:56:26.823167Z","shell.execute_reply":"2025-06-14T15:56:29.663807Z"}},"outputs":[{"name":"stdout","text":"Average ONNX inference time: 0.026949 sec\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"relative_speed=avg_pt_time/avg_onnx_time\nprint(f\"ONNX is {relative_speed:.2f}x faster than PyTorch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T15:58:51.785641Z","iopub.execute_input":"2025-06-14T15:58:51.786156Z","iopub.status.idle":"2025-06-14T15:58:51.793000Z","shell.execute_reply.started":"2025-06-14T15:58:51.786119Z","shell.execute_reply":"2025-06-14T15:58:51.791712Z"}},"outputs":[{"name":"stdout","text":"ONNX is 2.97x faster than PyTorch\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"speedup=((avg_pt_time-avg_onnx_time)/(avg_pt_time))*100\nprint(f\"ONNX model is {speedup:.2f}% faster than PyTorch model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T16:03:09.640466Z","iopub.execute_input":"2025-06-14T16:03:09.640859Z","iopub.status.idle":"2025-06-14T16:03:09.648696Z","shell.execute_reply.started":"2025-06-14T16:03:09.640832Z","shell.execute_reply":"2025-06-14T16:03:09.647333Z"}},"outputs":[{"name":"stdout","text":"ONNX model is 66.30% faster than PyTorch model\n","output_type":"stream"}],"execution_count":48}]}