{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-13T17:37:59.231455Z",
     "iopub.status.busy": "2025-06-13T17:37:59.231109Z",
     "iopub.status.idle": "2025-06-13T17:37:59.237180Z",
     "shell.execute_reply": "2025-06-13T17:37:59.236287Z",
     "shell.execute_reply.started": "2025-06-13T17:37:59.231432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Tokenizer\n",
    "import emoji\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from transformers import Trainer,TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:25:22.496168Z",
     "iopub.status.busy": "2025-06-13T17:25:22.495781Z",
     "iopub.status.idle": "2025-06-13T17:25:22.507052Z",
     "shell.execute_reply": "2025-06-13T17:25:22.506371Z",
     "shell.execute_reply.started": "2025-06-13T17:25:22.496145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(filename):\n",
    "    data = []\n",
    "    sentence = []\n",
    "    emojis = []\n",
    "\n",
    "    with open(f'/kaggle/input/emojifydata-en/{filename}.txt', 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if sentence:\n",
    "                    sent = \" \".join([w for w in sentence if w not in ['<START>', '<STOP>']])\n",
    "                    emjs = \"\".join(emojis)\n",
    "                    data.append((sent, emoji.emojize(emjs, language='alias')))\n",
    "                    sentence = []\n",
    "                    emojis = []\n",
    "            else:\n",
    "                if len(line.split()) == 2:\n",
    "                    word, tag = line.split()\n",
    "                    sentence.append(word)\n",
    "                    if tag != 'O':\n",
    "                        emojis.append(tag)\n",
    "\n",
    "        # Handle last sentence if file doesn‚Äôt end with a newline\n",
    "        if sentence:\n",
    "            sent = \" \".join([w for w in sentence if w not in ['<START>', '<STOP>']])\n",
    "            emjs = \"\".join(emojis)\n",
    "            data.append((sent, emoji.emojize(emjs, language='alias')))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Text', 'Emoji'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:31:10.932419Z",
     "iopub.status.busy": "2025-06-13T11:31:10.932178Z",
     "iopub.status.idle": "2025-06-13T11:32:52.065496Z",
     "shell.execute_reply": "2025-06-13T11:32:52.064908Z",
     "shell.execute_reply.started": "2025-06-13T11:31:10.932397Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99514776it [01:39, 999657.67it/s] \n"
     ]
    }
   ],
   "source": [
    "train_df=create_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:32:52.067670Z",
     "iopub.status.busy": "2025-06-13T11:32:52.067457Z",
     "iopub.status.idle": "2025-06-13T11:32:52.088438Z",
     "shell.execute_reply": "2025-06-13T11:32:52.087932Z",
     "shell.execute_reply.started": "2025-06-13T11:32:52.067652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CeeC is going to be another Tboss What is 45 m...</td>\n",
       "      <td>üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This gif kills me Death is literally gushing t...</td>\n",
       "      <td>üò©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOVE TEST Raw Real JaDine</td>\n",
       "      <td>üíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i swear we dont gotta look it finds us</td>\n",
       "      <td>üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We would like to wish everyone a very Happy Ne...</td>\n",
       "      <td>üéâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000 retweets a new song song off ‚Äú Swaecatio...</td>\n",
       "      <td>üó£Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>just know ilysm k bye friend</td>\n",
       "      <td>üíú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Too glam to give a damn</td>\n",
       "      <td>‚ú®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üèº üèº fuck that sicko</td>\n",
       "      <td>üëèüëè</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can I marry someone who understands all these ...</td>\n",
       "      <td>üò≠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Emoji\n",
       "0  CeeC is going to be another Tboss What is 45 m...     üòÇ\n",
       "1  This gif kills me Death is literally gushing t...     üò©\n",
       "2                          LOVE TEST Raw Real JaDine     üíú\n",
       "3             i swear we dont gotta look it finds us     üòÇ\n",
       "4  We would like to wish everyone a very Happy Ne...     üéâ\n",
       "5  15000 retweets a new song song off ‚Äú Swaecatio...    üó£Ô∏è\n",
       "6                       just know ilysm k bye friend     üíú\n",
       "7                            Too glam to give a damn     ‚ú®\n",
       "8                                üèº üèº fuck that sicko    üëèüëè\n",
       "9  Can I marry someone who understands all these ...     üò≠"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_emoji(text):\n",
    "    return [c for c in text if c in emoji.EMOJI_DATA]\n",
    "train_df['clean emoji']=train_df['Emoji'].apply(extract_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:02.595482Z",
     "iopub.status.busy": "2025-06-13T11:33:02.595295Z",
     "iopub.status.idle": "2025-06-13T11:33:02.605392Z",
     "shell.execute_reply": "2025-06-13T11:33:02.604846Z",
     "shell.execute_reply.started": "2025-06-13T11:33:02.595466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>clean emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CeeC is going to be another Tboss What is 45 m...</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>[üòÇ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This gif kills me Death is literally gushing t...</td>\n",
       "      <td>üò©</td>\n",
       "      <td>[üò©]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOVE TEST Raw Real JaDine</td>\n",
       "      <td>üíú</td>\n",
       "      <td>[üíú]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i swear we dont gotta look it finds us</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>[üòÇ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We would like to wish everyone a very Happy Ne...</td>\n",
       "      <td>üéâ</td>\n",
       "      <td>[üéâ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000 retweets a new song song off ‚Äú Swaecatio...</td>\n",
       "      <td>üó£Ô∏è</td>\n",
       "      <td>[üó£]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>just know ilysm k bye friend</td>\n",
       "      <td>üíú</td>\n",
       "      <td>[üíú]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Too glam to give a damn</td>\n",
       "      <td>‚ú®</td>\n",
       "      <td>[‚ú®]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>üèº üèº fuck that sicko</td>\n",
       "      <td>üëèüëè</td>\n",
       "      <td>[üëè, üëè]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can I marry someone who understands all these ...</td>\n",
       "      <td>üò≠</td>\n",
       "      <td>[üò≠]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Emoji clean emoji\n",
       "0  CeeC is going to be another Tboss What is 45 m...     üòÇ         [üòÇ]\n",
       "1  This gif kills me Death is literally gushing t...     üò©         [üò©]\n",
       "2                          LOVE TEST Raw Real JaDine     üíú         [üíú]\n",
       "3             i swear we dont gotta look it finds us     üòÇ         [üòÇ]\n",
       "4  We would like to wish everyone a very Happy Ne...     üéâ         [üéâ]\n",
       "5  15000 retweets a new song song off ‚Äú Swaecatio...    üó£Ô∏è         [üó£]\n",
       "6                       just know ilysm k bye friend     üíú         [üíú]\n",
       "7                            Too glam to give a damn     ‚ú®         [‚ú®]\n",
       "8                                üèº üèº fuck that sicko    üëèüëè      [üëè, üëè]\n",
       "9  Can I marry someone who understands all these ...     üò≠         [üò≠]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:02.606438Z",
     "iopub.status.busy": "2025-06-13T11:33:02.606131Z",
     "iopub.status.idle": "2025-06-13T11:33:05.836378Z",
     "shell.execute_reply": "2025-06-13T11:33:05.835597Z",
     "shell.execute_reply.started": "2025-06-13T11:33:02.606420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df =  train_df[train_df['clean emoji'].map(len) > 0].sample(n=500_000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:05.837454Z",
     "iopub.status.busy": "2025-06-13T11:33:05.837233Z",
     "iopub.status.idle": "2025-06-13T11:33:05.842384Z",
     "shell.execute_reply": "2025-06-13T11:33:05.841722Z",
     "shell.execute_reply.started": "2025-06-13T11:33:05.837435Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:05.843319Z",
     "iopub.status.busy": "2025-06-13T11:33:05.843080Z",
     "iopub.status.idle": "2025-06-13T11:33:14.656419Z",
     "shell.execute_reply": "2025-06-13T11:33:14.655618Z",
     "shell.execute_reply.started": "2025-06-13T11:33:05.843303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "emojis_in_data=set()\n",
    "for i in train_df.index:\n",
    "    emj=train_df.iloc[i]['clean emoji']\n",
    "    for j in emj:\n",
    "        emojis_in_data.update(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:14.659108Z",
     "iopub.status.busy": "2025-06-13T11:33:14.658502Z",
     "iopub.status.idle": "2025-06-13T11:33:14.664241Z",
     "shell.execute_reply": "2025-06-13T11:33:14.663722Z",
     "shell.execute_reply.started": "2025-06-13T11:33:14.659079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'‚Äº',\n",
       " '‚ò∫',\n",
       " '‚ôÄ',\n",
       " '‚ôÇ',\n",
       " '‚ô•',\n",
       " '‚úî',\n",
       " '‚ú®',\n",
       " '‚ù§',\n",
       " '‚û°',\n",
       " 'üåü',\n",
       " 'üéâ',\n",
       " 'üèÜ',\n",
       " 'üëÄ',\n",
       " 'üëá',\n",
       " 'üëâ',\n",
       " 'üëå',\n",
       " 'üëç',\n",
       " 'üëè',\n",
       " 'üíÄ',\n",
       " 'üíï',\n",
       " 'üíñ',\n",
       " 'üíô',\n",
       " 'üíõ',\n",
       " 'üíú',\n",
       " 'üí•',\n",
       " 'üí™',\n",
       " 'üíØ',\n",
       " 'üî•',\n",
       " 'üó£',\n",
       " 'üòÅ',\n",
       " 'üòÇ',\n",
       " 'üòâ',\n",
       " 'üòä',\n",
       " 'üòç',\n",
       " 'üòé',\n",
       " 'üòò',\n",
       " 'üò¢',\n",
       " 'üò©',\n",
       " 'üò≠',\n",
       " 'üò≥',\n",
       " 'üôÑ',\n",
       " 'üôå',\n",
       " 'üôè',\n",
       " 'üö®',\n",
       " 'ü§î',\n",
       " 'ü§£',\n",
       " 'ü§¶',\n",
       " 'ü§∑'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:14.665085Z",
     "iopub.status.busy": "2025-06-13T11:33:14.664885Z",
     "iopub.status.idle": "2025-06-13T11:33:15.083915Z",
     "shell.execute_reply": "2025-06-13T11:33:15.083217Z",
     "shell.execute_reply.started": "2025-06-13T11:33:14.665070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['clean emoji'].map(len) > 0].reset_index(drop=True)\n",
    "train_df\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:15.085082Z",
     "iopub.status.busy": "2025-06-13T11:33:15.084783Z",
     "iopub.status.idle": "2025-06-13T11:33:15.732226Z",
     "shell.execute_reply": "2025-06-13T11:33:15.731642Z",
     "shell.execute_reply.started": "2025-06-13T11:33:15.085056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mlb=MultiLabelBinarizer()\n",
    "emoji_label=mlb.fit_transform(train_df['clean emoji'])\n",
    "\n",
    "emoji_id_to_label={i:e for i,e in enumerate(mlb.classes_)}\n",
    "emoji_label_to_id={e:i for i,e in emoji_id_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:15.733167Z",
     "iopub.status.busy": "2025-06-13T11:33:15.732916Z",
     "iopub.status.idle": "2025-06-13T11:33:15.875346Z",
     "shell.execute_reply": "2025-06-13T11:33:15.874697Z",
     "shell.execute_reply.started": "2025-06-13T11:33:15.733144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df[\"labels\"] = list(emoji_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:15.876506Z",
     "iopub.status.busy": "2025-06-13T11:33:15.876239Z",
     "iopub.status.idle": "2025-06-13T11:33:21.272496Z",
     "shell.execute_reply": "2025-06-13T11:33:21.271845Z",
     "shell.execute_reply.started": "2025-06-13T11:33:15.876484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=True)\n",
    "num_labels=emoji_label.shape[1]\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"vinai/bertweet-base\",\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:33:21.273582Z",
     "iopub.status.busy": "2025-06-13T11:33:21.273321Z",
     "iopub.status.idle": "2025-06-13T11:33:23.379959Z",
     "shell.execute_reply": "2025-06-13T11:33:23.379075Z",
     "shell.execute_reply.started": "2025-06-13T11:33:21.273556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acac34163e64025b7e15016b3c2a614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(train_df[[\"Text\", \"labels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    tokens[\"labels\"] = example[\"labels\"]\n",
    "    return tokens\n",
    "    \n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:34:32.807074Z",
     "iopub.status.busy": "2025-06-13T11:34:32.806305Z",
     "iopub.status.idle": "2025-06-13T11:35:15.283992Z",
     "shell.execute_reply": "2025-06-13T11:35:15.283368Z",
     "shell.execute_reply.started": "2025-06-13T11:34:32.807049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90925f8568c4e74bae4b1cd4367b606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_dataset = tokenized_dataset.map(\n",
    "    lambda x: {\"labels\": [list(map(float, l)) for l in x[\"labels\"]]},\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:31:33.182525Z",
     "iopub.status.busy": "2025-06-13T17:31:33.182189Z",
     "iopub.status.idle": "2025-06-13T17:31:33.187080Z",
     "shell.execute_reply": "2025-06-13T17:31:33.186246Z",
     "shell.execute_reply.started": "2025-06-13T17:31:33.182507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        for f in features:\n",
    "            f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n",
    "        return super().__call__(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:35:15.290078Z",
     "iopub.status.busy": "2025-06-13T11:35:15.289852Z",
     "iopub.status.idle": "2025-06-13T11:35:15.307090Z",
     "shell.execute_reply": "2025-06-13T11:35:15.306457Z",
     "shell.execute_reply.started": "2025-06-13T11:35:15.290055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T11:35:15.308236Z",
     "iopub.status.busy": "2025-06-13T11:35:15.307989Z",
     "iopub.status.idle": "2025-06-13T15:14:31.750940Z",
     "shell.execute_reply": "2025-06-13T15:14:31.750135Z",
     "shell.execute_reply.started": "2025-06-13T11:35:15.308215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2978934322.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/tmp/ipykernel_35/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62500/62500 3:39:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.072300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.070600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.070200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.067700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.067600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.060900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.060500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.060100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.060100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.059400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.059400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.059000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62500, training_loss=0.0674023611755371, metrics={'train_runtime': 13154.7956, 'train_samples_per_second': 76.018, 'train_steps_per_second': 4.751, 'total_flos': 6.5804931072e+16, 'train_loss': 0.0674023611755371, 'epoch': 2.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = CustomDataCollator(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='tweet-emoji',\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=1000,\n",
    "    # evaluation_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:14:45.285259Z",
     "iopub.status.busy": "2025-06-13T15:14:45.284609Z",
     "iopub.status.idle": "2025-06-13T15:14:45.609420Z",
     "shell.execute_reply": "2025-06-13T15:14:45.608580Z",
     "shell.execute_reply.started": "2025-06-13T15:14:45.285238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! mkdir /kaggle/working/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:15:28.511910Z",
     "iopub.status.busy": "2025-06-13T15:15:28.511602Z",
     "iopub.status.idle": "2025-06-13T15:15:29.366551Z",
     "shell.execute_reply": "2025-06-13T15:15:29.365930Z",
     "shell.execute_reply.started": "2025-06-13T15:15:28.511858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model\\\\mlb_emoji_encoder.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir='model'\n",
    "model.save_pretrained(model_dir,save_serialization=True)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "joblib.dump(mlb,'model\\mlb_emoji_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:16:20.046372Z",
     "iopub.status.busy": "2025-06-13T15:16:20.045383Z",
     "iopub.status.idle": "2025-06-13T15:16:20.376409Z",
     "shell.execute_reply": "2025-06-13T15:16:20.375679Z",
     "shell.execute_reply.started": "2025-06-13T15:16:20.046343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: missing operand\n",
      "Try 'mkdir --help' for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/model/mlb_emoji_encoder.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlb,'/kaggle/working/model/mlb_emoji_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:17:43.086634Z",
     "iopub.status.busy": "2025-06-13T15:17:43.086133Z",
     "iopub.status.idle": "2025-06-13T15:17:43.091680Z",
     "shell.execute_reply": "2025-06-13T15:17:43.091121Z",
     "shell.execute_reply.started": "2025-06-13T15:17:43.086601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['‚Äº', '‚ò∫', '‚ôÄ', '‚ôÇ', '‚ô•', '‚úî', '‚ú®', '‚ù§', '‚û°', 'üåü', 'üéâ', 'üèÜ', 'üëÄ',\n",
       "       'üëá', 'üëâ', 'üëå', 'üëç', 'üëè', 'üíÄ', 'üíï', 'üíñ', 'üíô', 'üíõ', 'üíú', 'üí•', 'üí™',\n",
       "       'üíØ', 'üî•', 'üó£', 'üòÅ', 'üòÇ', 'üòâ', 'üòä', 'üòç', 'üòé', 'üòò', 'üò¢', 'üò©', 'üò≠',\n",
       "       'üò≥', 'üôÑ', 'üôå', 'üôè', 'üö®', 'ü§î', 'ü§£', 'ü§¶', 'ü§∑'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:17:48.124947Z",
     "iopub.status.busy": "2025-06-13T15:17:48.124645Z",
     "iopub.status.idle": "2025-06-13T15:18:16.322540Z",
     "shell.execute_reply": "2025-06-13T15:18:16.321935Z",
     "shell.execute_reply.started": "2025-06-13T15:17:48.124926Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/tweet_emoji_bert.zip'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('tweet_emoji_bert', 'zip', '/kaggle/working/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T15:18:58.752732Z",
     "iopub.status.busy": "2025-06-13T15:18:58.752035Z",
     "iopub.status.idle": "2025-06-13T15:19:04.729026Z",
     "shell.execute_reply": "2025-06-13T15:19:04.728097Z",
     "shell.execute_reply.started": "2025-06-13T15:18:58.752702Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:56:50.338608Z",
     "iopub.status.busy": "2025-06-13T17:56:50.337845Z",
     "iopub.status.idle": "2025-06-13T17:56:50.448322Z",
     "shell.execute_reply": "2025-06-13T17:56:50.447746Z",
     "shell.execute_reply.started": "2025-06-13T17:56:50.338585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:19:25.941588Z",
     "iopub.status.busy": "2025-06-13T15:19:25.941057Z",
     "iopub.status.idle": "2025-06-13T15:19:25.945730Z",
     "shell.execute_reply": "2025-06-13T15:19:25.945007Z",
     "shell.execute_reply.started": "2025-06-13T15:19:25.941564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T15:19:29.681133Z",
     "iopub.status.busy": "2025-06-13T15:19:29.680557Z",
     "iopub.status.idle": "2025-06-13T15:19:29.882392Z",
     "shell.execute_reply": "2025-06-13T15:19:29.881811Z",
     "shell.execute_reply.started": "2025-06-13T15:19:29.681107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T16:13:48.279515Z",
     "iopub.status.busy": "2025-06-13T16:13:48.279254Z",
     "iopub.status.idle": "2025-06-13T16:13:48.317180Z",
     "shell.execute_reply": "2025-06-13T16:13:48.316643Z",
     "shell.execute_reply.started": "2025-06-13T16:13:48.279498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3684618998.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,  \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T16:13:51.409568Z",
     "iopub.status.busy": "2025-06-13T16:13:51.408862Z",
     "iopub.status.idle": "2025-06-13T16:48:26.486195Z",
     "shell.execute_reply": "2025-06-13T16:48:26.485422Z",
     "shell.execute_reply.started": "2025-06-13T16:13:51.409546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62500/62500 34:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics: {'eval_loss': 0.05261430889368057, 'eval_model_preparation_time': 0.0033, 'eval_accuracy': 0.398562, 'eval_f1': 0.5596929174318587, 'eval_runtime': 2075.0598, 'eval_samples_per_second': 240.957, 'eval_steps_per_second': 30.12}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "train_metrics = trainer.evaluate(eval_dataset=tokenized_dataset)\n",
    "print(\"Training Set Metrics:\", train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_df=create_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valid_df['clean emoji']=valid_df['Emoji'].apply(extract_emoji)\n",
    "emoji_label=mlb.transform(valid_df['clean emoji'])\n",
    "valid_df[\"labels\"] = list(emoji_label)\n",
    "\n",
    "val_dataset = Dataset.from_pandas(valid_df[[\"Text\", \"labels\"]])\n",
    "val_tokenized_dataset = val_dataset.map(tokenize_function, batched=True, num_proc=4)\n",
    "val_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_tokenized_dataset = val_tokenized_dataset.map(\n",
    "    lambda x: {\"labels\": [list(map(float, l)) for l in x[\"labels\"]]},\n",
    "    batched=True\n",
    ")\n",
    "val_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_tokenized_dataset)\n",
    "print(\"Validation Set Metrics:\", val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:56:42.341224Z",
     "iopub.status.busy": "2025-06-13T18:56:42.340532Z",
     "iopub.status.idle": "2025-06-13T18:56:42.537926Z",
     "shell.execute_reply": "2025-06-13T18:56:42.537100Z",
     "shell.execute_reply.started": "2025-06-13T18:56:42.341188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model\")\n",
    "mlb=joblib.load('/kaggle/working/model/mlb_emoji_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:56:43.679807Z",
     "iopub.status.busy": "2025-06-13T18:56:43.679284Z",
     "iopub.status.idle": "2025-06-13T18:56:43.685728Z",
     "shell.execute_reply": "2025-06-13T18:56:43.685169Z",
     "shell.execute_reply.started": "2025-06-13T18:56:43.679783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=48, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:21:21.728604Z",
     "iopub.status.busy": "2025-06-13T17:21:21.727816Z",
     "iopub.status.idle": "2025-06-13T17:21:21.734021Z",
     "shell.execute_reply": "2025-06-13T17:21:21.733166Z",
     "shell.execute_reply.started": "2025-06-13T17:21:21.728567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_emojis(text):\n",
    "    model.eval()\n",
    "    inputs=tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs=model(**inputs)\n",
    "        print(outputs.logits)\n",
    "        probs=torch.sigmoid(outputs.logits)\n",
    "        print(probs)\n",
    "        predictions=(probs>=0.3).int().numpy()\n",
    "    print(predictions)\n",
    "\n",
    "    return mlb.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:21:12.677498Z",
     "iopub.status.busy": "2025-06-13T17:21:12.676980Z",
     "iopub.status.idle": "2025-06-13T17:21:12.820130Z",
     "shell.execute_reply": "2025-06-13T17:21:12.819381Z",
     "shell.execute_reply.started": "2025-06-13T17:21:12.677475Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.9818, -3.2426, -7.5848, -9.5882, -5.2063, -6.5351, -3.4494, -3.4749,\n",
      "         -8.4590, -5.3543, -4.9825, -7.8210, -5.3048, -6.4848, -6.7298, -4.4016,\n",
      "         -3.0211, -5.8498, -7.4705, -2.6714, -3.8847, -4.0045, -4.1654, -3.9560,\n",
      "         -7.2476, -5.9317, -6.0126, -6.0635, -7.9244, -2.0577, -2.8466, -2.5008,\n",
      "         -0.2568, -3.1581, -3.9901, -3.1193, -6.1196, -5.9622, -4.9209, -6.3456,\n",
      "         -4.9971, -5.3569, -4.7934, -8.4494, -5.0017, -5.1919, -9.6236, -6.9423]])\n",
      "tensor([[4.6230e-05, 3.7592e-02, 5.0787e-04, 6.8531e-05, 5.4521e-03, 1.4494e-03,\n",
      "         3.0786e-02, 3.0036e-02, 2.1194e-04, 4.7054e-03, 6.8100e-03, 4.0108e-04,\n",
      "         4.9432e-03, 1.5242e-03, 1.1933e-03, 1.2109e-02, 4.6481e-02, 2.8721e-03,\n",
      "         5.6934e-04, 6.4679e-02, 2.0140e-02, 1.7908e-02, 1.5287e-02, 1.8780e-02,\n",
      "         7.1138e-04, 2.6469e-03, 2.4416e-03, 2.3208e-03, 3.6169e-04, 1.1328e-01,\n",
      "         5.4859e-02, 7.5801e-02, 4.3615e-01, 4.0774e-02, 1.8161e-02, 4.2316e-02,\n",
      "         2.1946e-03, 2.5677e-03, 7.2394e-03, 1.7513e-03, 6.7119e-03, 4.6935e-03,\n",
      "         8.2165e-03, 2.1399e-04, 6.6814e-03, 5.5307e-03, 6.6142e-05, 9.6516e-04]])\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üòä',)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emojis(\"It is gonna be fun today, will play games and do fun activities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:21:24.276692Z",
     "iopub.status.busy": "2025-06-13T17:21:24.276190Z",
     "iopub.status.idle": "2025-06-13T17:21:24.423582Z",
     "shell.execute_reply": "2025-06-13T17:21:24.422731Z",
     "shell.execute_reply.started": "2025-06-13T17:21:24.276666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.3065,  -6.8796,  -7.9452,  -9.8666,  -8.4167,  -9.4749,  -6.8766,\n",
      "          -6.6593, -10.2658,  -8.7952,  -7.2954,  -9.4924,  -6.0826,  -8.7549,\n",
      "          -9.4072,  -6.9320,  -6.5513,  -6.2663,  -5.2185,  -6.2692,  -6.9855,\n",
      "          -7.2521,  -7.4664,  -7.4758,  -7.7659,  -7.4456,  -5.9887,  -6.6328,\n",
      "          -7.1367,  -5.2754,  -2.7389,  -6.2015,  -4.4402,  -5.4425,  -6.3196,\n",
      "          -6.8769,  -2.4257,  -0.9126,  -0.7196,  -5.1986,  -1.3077,  -6.6778,\n",
      "          -5.7267,  -8.6202,  -4.1181,  -5.3393,  -6.4791,  -7.3667]])\n",
      "tensor([[3.3415e-05, 1.0275e-03, 3.5424e-04, 5.1877e-05, 2.2110e-04, 7.6748e-05,\n",
      "         1.0306e-03, 1.2804e-03, 3.4801e-05, 1.5144e-04, 6.7823e-04, 7.5414e-05,\n",
      "         2.2771e-03, 1.5766e-04, 8.2122e-05, 9.7507e-04, 1.4262e-03, 1.8957e-03,\n",
      "         5.3865e-03, 1.8901e-03, 9.2437e-04, 7.0817e-04, 5.7166e-04, 5.6632e-04,\n",
      "         4.2378e-04, 5.8367e-04, 2.5007e-03, 1.3148e-03, 7.9476e-04, 5.0901e-03,\n",
      "         6.0714e-02, 2.0223e-03, 1.1656e-02, 4.3100e-03, 1.7975e-03, 1.0303e-03,\n",
      "         8.1237e-02, 2.8646e-01, 3.2748e-01, 5.4941e-03, 2.1288e-01, 1.2570e-03,\n",
      "         3.2472e-03, 1.8039e-04, 1.6015e-02, 4.7764e-03, 1.5328e-03, 6.3157e-04]])\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üò≠',)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emojis(\"It is gonna be boring today, I don't have anything to do\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding correct threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:26:23.286932Z",
     "iopub.status.busy": "2025-06-13T17:26:23.286096Z",
     "iopub.status.idle": "2025-06-13T17:26:47.775925Z",
     "shell.execute_reply": "2025-06-13T17:26:47.775328Z",
     "shell.execute_reply.started": "2025-06-13T17:26:23.286902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24885251it [00:24, 1033217.78it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_df=create_dataset('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:55:38.194111Z",
     "iopub.status.busy": "2025-06-13T17:55:38.193310Z",
     "iopub.status.idle": "2025-06-13T17:56:17.252623Z",
     "shell.execute_reply": "2025-06-13T17:56:17.251672Z",
     "shell.execute_reply.started": "2025-06-13T17:55:38.194084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d32fa1dd1264d1694bb3aa9e7c05324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f81f0393d84fe5bb121241e307e021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386/3242046520.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  f['labels'] = torch.tensor(f['labels'], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "valid_df['clean emoji']=valid_df['Emoji'].apply(extract_emoji)\n",
    "valid_df = valid_df[valid_df['clean emoji'].map(len) > 0].sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "emoji_label=mlb.transform(valid_df['clean emoji'])\n",
    "valid_df[\"labels\"] = list(emoji_label)\n",
    "\n",
    "val_dataset = Dataset.from_pandas(valid_df[[\"Text\", \"labels\"]])\n",
    "\n",
    "val_tokenized_dataset = val_dataset.map(tokenize_function, batched=True, num_proc=4)\n",
    "val_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_tokenized_dataset = val_tokenized_dataset.map(\n",
    "    lambda x: {\"labels\": [list(map(float, l)) for l in x[\"labels\"]]},\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "val_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "data_collator = CustomDataCollator(tokenizer=tokenizer)\n",
    "\n",
    "valid_loader=DataLoader(val_tokenized_dataset,batch_size=32,collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "all_logits=[]\n",
    "all_labels=[]\n",
    "\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        input_ids=batch['input_ids'].to(model.device)\n",
    "        attention_mask=batch['attention_mask'].to(model.device)\n",
    "        labels=batch['labels'].to(model.device)\n",
    "\n",
    "        outputs=model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        logits=outputs.logits\n",
    "\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "logits=torch.cat(all_logits).numpy()\n",
    "labels=torch.cat(all_labels).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:56:35.761243Z",
     "iopub.status.busy": "2025-06-13T17:56:35.760628Z",
     "iopub.status.idle": "2025-06-13T17:56:35.766906Z",
     "shell.execute_reply": "2025-06-13T17:56:35.766039Z",
     "shell.execute_reply.started": "2025-06-13T17:56:35.761212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tune_thresholds(y_true,y_probs):\n",
    "    thresholds=[]\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if y_true[:,i].sum()==0:\n",
    "            threshold.append(0.5)\n",
    "            continue\n",
    "        best_thresh=0.5\n",
    "        best_f1=0\n",
    "        for thresh in np.arange(0.1,0.9,0.05):\n",
    "            preds=(y_probs[:,i]>=thresh).astype(int)\n",
    "            score=f1_score(y_true[:,i],preds,zero_division=0)\n",
    "            if score>best_f1:\n",
    "                best_f1=score\n",
    "                best_thresh=thresh\n",
    "        thresholds.append(best_thresh)\n",
    "    return np.array(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:56:55.353849Z",
     "iopub.status.busy": "2025-06-13T17:56:55.353139Z",
     "iopub.status.idle": "2025-06-13T17:56:59.750524Z",
     "shell.execute_reply": "2025-06-13T17:56:59.749615Z",
     "shell.execute_reply.started": "2025-06-13T17:56:55.353825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tuned_thresholds_=tune_thresholds(labels,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:58:45.040765Z",
     "iopub.status.busy": "2025-06-13T17:58:45.040480Z",
     "iopub.status.idle": "2025-06-13T17:58:45.045896Z",
     "shell.execute_reply": "2025-06-13T17:58:45.045189Z",
     "shell.execute_reply.started": "2025-06-13T17:58:45.040745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes not present in validation set: []\n"
     ]
    }
   ],
   "source": [
    "missing_classes = np.where(labels.sum(axis=0) == 0)[0]\n",
    "print(f\"Classes not present in validation set: {missing_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:00:55.237426Z",
     "iopub.status.busy": "2025-06-13T18:00:55.236845Z",
     "iopub.status.idle": "2025-06-13T18:00:55.242853Z",
     "shell.execute_reply": "2025-06-13T18:00:55.242123Z",
     "shell.execute_reply.started": "2025-06-13T18:00:55.237403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.15, 0.1 , 0.1 , 0.15, 0.25,\n",
       "       0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.3 , 0.5 , 0.1 , 0.1 ,\n",
       "       0.5 , 0.1 , 0.5 , 0.1 , 0.1 , 0.1 , 0.1 , 0.5 , 0.1 , 0.5 , 0.1 ,\n",
       "       0.1 , 0.5 , 0.1 , 0.1 , 0.35, 0.1 , 0.1 , 0.1 , 0.1 , 0.2 , 0.15,\n",
       "       0.25, 0.5 , 0.1 , 0.1 ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_thresholds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:56:55.703005Z",
     "iopub.status.busy": "2025-06-13T18:56:55.702404Z",
     "iopub.status.idle": "2025-06-13T18:56:55.712589Z",
     "shell.execute_reply": "2025-06-13T18:56:55.711840Z",
     "shell.execute_reply.started": "2025-06-13T18:56:55.702980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "def predict_emojis(text):\n",
    "    thresholds=np.array([0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.15, 0.1 , 0.1 , 0.15, 0.25,\n",
    "       0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.3 , 0.5 , 0.1 , 0.1 ,\n",
    "       0.5 , 0.1 , 0.5 , 0.1 , 0.1 , 0.1 , 0.1 , 0.5 , 0.1 , 0.5 , 0.1 ,\n",
    "       0.1 , 0.5 , 0.1 , 0.1 , 0.35, 0.1 , 0.1 , 0.1 , 0.1 , 0.2 , 0.15,\n",
    "       0.25, 0.5 , 0.1 , 0.1 ])\n",
    "    model.eval()\n",
    "    inputs=tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    predictions=[]\n",
    "    with torch.no_grad():\n",
    "        outputs=model(**inputs)\n",
    "        probs=torch.sigmoid(outputs.logits).squeeze(0).numpy()\n",
    "\n",
    "    predicted_labels=(probs>=thresholds).astype(int).reshape(1,-1)\n",
    "\n",
    "    return mlb.inverse_transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:56:56.697095Z",
     "iopub.status.busy": "2025-06-13T18:56:56.696354Z",
     "iopub.status.idle": "2025-06-13T18:56:56.870990Z",
     "shell.execute_reply": "2025-06-13T18:56:56.870355Z",
     "shell.execute_reply.started": "2025-06-13T18:56:56.697068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üò≠', 'üôÑ')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emojis(\"It is gonna be boring today, I don't have anything to do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:56:58.093621Z",
     "iopub.status.busy": "2025-06-13T18:56:58.093331Z",
     "iopub.status.idle": "2025-06-13T18:56:58.251709Z",
     "shell.execute_reply": "2025-06-13T18:56:58.251069Z",
     "shell.execute_reply.started": "2025-06-13T18:56:58.093600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üí™', 'üî•')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emojis(\"It is gonna be fun today, will play games and do fun activities. Lets go!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T14:19:14.376862Z",
     "iopub.status.busy": "2025-06-14T14:19:14.376433Z",
     "iopub.status.idle": "2025-06-14T14:21:07.220262Z",
     "shell.execute_reply": "2025-06-14T14:21:07.218705Z",
     "shell.execute_reply.started": "2025-06-14T14:19:14.376825Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install onnx onnxruntime optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T14:44:21.981078Z",
     "iopub.status.busy": "2025-06-14T14:44:21.980547Z",
     "iopub.status.idle": "2025-06-14T14:44:39.541100Z",
     "shell.execute_reply": "2025-06-14T14:44:39.539523Z",
     "shell.execute_reply.started": "2025-06-14T14:44:21.981046Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade optimum[onnxruntime] transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:44:46.265245Z",
     "iopub.status.busy": "2025-06-14T14:44:46.264864Z",
     "iopub.status.idle": "2025-06-14T14:44:46.272831Z",
     "shell.execute_reply": "2025-06-14T14:44:46.271504Z",
     "shell.execute_reply.started": "2025-06-14T14:44:46.265216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers.onnx import export\n",
    "from pathlib import Path\n",
    "from transformers.onnx.features import FeaturesManager\n",
    "from onnxruntime.quantization import quantize_dynamic,QuantType\n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "from optimum.exporters.tasks import TasksManager\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from optimum.onnxruntime import ORTQuantizer\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification, ORTQuantizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:26:00.822003Z",
     "iopub.status.busy": "2025-06-14T14:26:00.821278Z",
     "iopub.status.idle": "2025-06-14T14:26:04.028008Z",
     "shell.execute_reply": "2025-06-14T14:26:04.026671Z",
     "shell.execute_reply.started": "2025-06-14T14:26:00.821967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80be1272962d4f438b8a4f6a806f0e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215c5ac5c2a047dfb395a55b397b5572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained(\"ashish-001/tweet-emoji-predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:26:20.815685Z",
     "iopub.status.busy": "2025-06-14T14:26:20.815306Z",
     "iopub.status.idle": "2025-06-14T14:26:23.158426Z",
     "shell.execute_reply": "2025-06-14T14:26:23.157353Z",
     "shell.execute_reply.started": "2025-06-14T14:26:20.815658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8211156ab14009881b04cc3e4a6bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f702295590bf4d128b08209087176293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5875c0c46c4df6b7c6134fd423bd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2868e870344d427e8a5f0b1a24d2e697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0174378a31244ddda3c6c5e40f6b4eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"ashish-001/tweet-emoji-predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PYTORCH_MODEL_DIR = \"ashish-001/tweet-emoji-predictor\"  \n",
    "ONNX_UNQUANTIZED_DIR = Path(\"onnx_unquantized\")\n",
    "QUANTIZED_MODEL_DIR = Path(\"onnx_quantized_dynamic\")\n",
    "\n",
    "print(\"STAGE 1: Exporting PyTorch model to ONNX ---\")\n",
    "\n",
    "\n",
    "model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    PYTORCH_MODEL_DIR,\n",
    "    export=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(PYTORCH_MODEL_DIR)\n",
    "\n",
    "\n",
    "model.save_pretrained(ONNX_UNQUANTIZED_DIR)\n",
    "tokenizer.save_pretrained(ONNX_UNQUANTIZED_DIR)\n",
    "\n",
    "print(f\"Unquantized ONNX model saved to: {ONNX_UNQUANTIZED_DIR}\")\n",
    "\n",
    "\n",
    "print(\"STAGE 2: Applying Dynamic Quantization ---\")\n",
    "\n",
    "\n",
    "quantizer = ORTQuantizer.from_pretrained(ONNX_UNQUANTIZED_DIR)\n",
    "\n",
    "\n",
    "dqconfig = AutoQuantizationConfig.avx2(is_static=False, per_channel=False)\n",
    "\n",
    "\n",
    "quantizer.quantize(\n",
    "    save_dir=QUANTIZED_MODEL_DIR,\n",
    "    quantization_config=dqconfig,\n",
    ")\n",
    "\n",
    "print(f\"Dynamically quantized model saved to: {QUANTIZED_MODEL_DIR}\")\n",
    "\n",
    "\n",
    "print(\"STAGE 3: Running Inference ---\")\n",
    "\n",
    "\n",
    "quantized_model_path = QUANTIZED_MODEL_DIR / \"model_quantized.onnx\"\n",
    "\n",
    "session = ort.InferenceSession(str(quantized_model_path))\n",
    "\n",
    "\n",
    "text = \"This is a sample text for inference.\"\n",
    "inputs = tokenizer(text, return_tensors=\"np\")\n",
    "\n",
    "\n",
    "onnx_inputs = {\n",
    "    \"input_ids\": inputs[\"input_ids\"].astype(np.int64),\n",
    "    \"attention_mask\": inputs[\"attention_mask\"].astype(np.int64),\n",
    "}\n",
    "\n",
    "\n",
    "logits = session.run(None, onnx_inputs)[0]\n",
    "\n",
    "print(\"Inference successful!\")\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
    "print(\"Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing finetuned model and onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:54:23.539817Z",
     "iopub.status.busy": "2025-06-14T15:54:23.539367Z",
     "iopub.status.idle": "2025-06-14T15:54:23.547235Z",
     "shell.execute_reply": "2025-06-14T15:54:23.545652Z",
     "shell.execute_reply.started": "2025-06-14T15:54:23.539761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:47:15.086650Z",
     "iopub.status.busy": "2025-06-14T15:47:15.086081Z",
     "iopub.status.idle": "2025-06-14T15:47:16.741395Z",
     "shell.execute_reply": "2025-06-14T15:47:16.739332Z",
     "shell.execute_reply.started": "2025-06-14T15:47:15.086608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained(\"ashish-001/tweet-emoji-predictor\")\n",
    "session = ort.InferenceSession(str(quantized_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T15:47:34.116501Z",
     "iopub.status.busy": "2025-06-14T15:47:34.116133Z",
     "iopub.status.idle": "2025-06-14T15:47:34.128523Z",
     "shell.execute_reply": "2025-06-14T15:47:34.126846Z",
     "shell.execute_reply.started": "2025-06-14T15:47:34.116474Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=48, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:54:34.305226Z",
     "iopub.status.busy": "2025-06-14T15:54:34.304149Z",
     "iopub.status.idle": "2025-06-14T15:54:42.819452Z",
     "shell.execute_reply": "2025-06-14T15:54:42.818459Z",
     "shell.execute_reply.started": "2025-06-14T15:54:34.305183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PyTorch inference time: 0.079958 sec\n"
     ]
    }
   ],
   "source": [
    "text=\"Sample input for timing comparison\"\n",
    "input_pt=tokenizer(text,return_tensors=\"pt\")\n",
    "\n",
    "for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        _=model(**input_pt)\n",
    "\n",
    "# Measure\n",
    "start_time=time.time()\n",
    "for _ in range(100):\n",
    "    with torch.no_grad():\n",
    "        _=model(**input_pt)\n",
    "end_time=time.time()\n",
    "\n",
    "avg_pt_time=(end_time-start_time)/100\n",
    "print(f\"Average PyTorch inference time: {avg_pt_time:.6f} sec\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:56:26.823196Z",
     "iopub.status.busy": "2025-06-14T15:56:26.822820Z",
     "iopub.status.idle": "2025-06-14T15:56:29.665005Z",
     "shell.execute_reply": "2025-06-14T15:56:29.663807Z",
     "shell.execute_reply.started": "2025-06-14T15:56:26.823167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ONNX inference time: 0.026949 sec\n"
     ]
    }
   ],
   "source": [
    "input_np=tokenizer(text,return_tensors=\"np\")\n",
    "onnx_inputs = {\n",
    "    \"input_ids\": input_np[\"input_ids\"].astype(np.int64),\n",
    "    \"attention_mask\": input_np[\"attention_mask\"].astype(np.int64),\n",
    "}\n",
    "\n",
    "for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        _=session.run(None,onnx_inputs)\n",
    "\n",
    "# Measure\n",
    "start_time=time.time()\n",
    "for _ in range(100):\n",
    "    with torch.no_grad():\n",
    "        _=session.run(None,onnx_inputs)\n",
    "end_time=time.time()\n",
    "\n",
    "avg_onnx_time=(end_time-start_time)/100\n",
    "print(f\"Average ONNX inference time: {avg_onnx_time:.6f} sec\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T15:58:51.786156Z",
     "iopub.status.busy": "2025-06-14T15:58:51.785641Z",
     "iopub.status.idle": "2025-06-14T15:58:51.793000Z",
     "shell.execute_reply": "2025-06-14T15:58:51.791712Z",
     "shell.execute_reply.started": "2025-06-14T15:58:51.786119Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX is 2.97x faster than PyTorch\n"
     ]
    }
   ],
   "source": [
    "relative_speed=avg_pt_time/avg_onnx_time\n",
    "print(f\"ONNX is {relative_speed:.2f}x faster than PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T16:03:09.640859Z",
     "iopub.status.busy": "2025-06-14T16:03:09.640466Z",
     "iopub.status.idle": "2025-06-14T16:03:09.648696Z",
     "shell.execute_reply": "2025-06-14T16:03:09.647333Z",
     "shell.execute_reply.started": "2025-06-14T16:03:09.640832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is 66.30% faster than PyTorch model\n"
     ]
    }
   ],
   "source": [
    "speedup=((avg_pt_time-avg_onnx_time)/(avg_pt_time))*100\n",
    "print(f\"ONNX model is {speedup:.2f}% faster than PyTorch model\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 198119,
     "sourceId": 450483,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
